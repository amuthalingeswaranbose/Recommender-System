{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amuthalingeswaranbose/Recommender-System/blob/master/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "P4MN6mzFeocB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Created on Dec 8, 2015\n",
        "@author: donghyun\n",
        "'''\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from util import eval_RMSE\n",
        "import math\n",
        "import numpy as np\n",
        "from text_analysis.models import CNN_module\n",
        "\n",
        "\n",
        "def ConvMF(res_dir, train_user, train_item, valid_user, test_user,\n",
        "           R, CNN_X, vocab_size, init_W=None, give_item_weight=True,\n",
        "           max_iter=50, lambda_u=1, lambda_v=100, dimension=50,\n",
        "           dropout_rate=0.2, emb_dim=200, max_len=300, num_kernel_per_ws=100):\n",
        "    # explicit setting\n",
        "    a = 1\n",
        "    b = 0\n",
        "\n",
        "    num_user = R.shape[0]\n",
        "    num_item = R.shape[1]\n",
        "    PREV_LOSS = 1e-50\n",
        "    if not os.path.exists(res_dir):\n",
        "        os.makedirs(res_dir)\n",
        "    f1 = open(res_dir + '/state.log', 'w')\n",
        "\n",
        "    Train_R_I = train_user[1]\n",
        "    Train_R_J = train_item[1]\n",
        "    Test_R = test_user[1]\n",
        "    Valid_R = valid_user[1]\n",
        "\n",
        "    if give_item_weight is True:\n",
        "        item_weight = np.array([math.sqrt(len(i))\n",
        "                                for i in Train_R_J], dtype=float)\n",
        "        item_weight = (float(num_item) / item_weight.sum()) * item_weight\n",
        "    else:\n",
        "        item_weight = np.ones(num_item, dtype=float)\n",
        "\n",
        "    pre_val_eval = 1e10\n",
        "\n",
        "    cnn_module = CNN_module(dimension, vocab_size, dropout_rate,\n",
        "                            emb_dim, max_len, num_kernel_per_ws, init_W)\n",
        "    theta = cnn_module.get_projection_layer(CNN_X)\n",
        "    np.random.seed(133)\n",
        "    U = np.random.uniform(size=(num_user, dimension))\n",
        "    V = theta\n",
        "\n",
        "    endure_count = 5\n",
        "    count = 0\n",
        "    for iteration in xrange(max_iter):\n",
        "        loss = 0\n",
        "        tic = time.time()\n",
        "        print \"%d iteration\\t(patience: %d)\" % (iteration, count)\n",
        "\n",
        "        VV = b * (V.T.dot(V)) + lambda_u * np.eye(dimension)\n",
        "        sub_loss = np.zeros(num_user)\n",
        "\n",
        "        for i in xrange(num_user):\n",
        "            idx_item = train_user[0][i]\n",
        "            V_i = V[idx_item]\n",
        "            R_i = Train_R_I[i]\n",
        "            A = VV + (a - b) * (V_i.T.dot(V_i))\n",
        "            B = (a * V_i * (np.tile(R_i, (dimension, 1)).T)).sum(0)\n",
        "\n",
        "            U[i] = np.linalg.solve(A, B)\n",
        "\n",
        "            sub_loss[i] = -0.5 * lambda_u * np.dot(U[i], U[i])\n",
        "\n",
        "        loss = loss + np.sum(sub_loss)\n",
        "\n",
        "        sub_loss = np.zeros(num_item)\n",
        "        UU = b * (U.T.dot(U))\n",
        "        for j in xrange(num_item):\n",
        "            idx_user = train_item[0][j]\n",
        "            U_j = U[idx_user]\n",
        "            R_j = Train_R_J[j]\n",
        "\n",
        "            tmp_A = UU + (a - b) * (U_j.T.dot(U_j))\n",
        "            A = tmp_A + lambda_v * item_weight[j] * np.eye(dimension)\n",
        "            B = (a * U_j * (np.tile(R_j, (dimension, 1)).T)\n",
        "                 ).sum(0) + lambda_v * item_weight[j] * theta[j]\n",
        "            V[j] = np.linalg.solve(A, B)\n",
        "\n",
        "            sub_loss[j] = -0.5 * np.square(R_j * a).sum()\n",
        "            sub_loss[j] = sub_loss[j] + a * np.sum((U_j.dot(V[j])) * R_j)\n",
        "            sub_loss[j] = sub_loss[j] - 0.5 * np.dot(V[j].dot(tmp_A), V[j])\n",
        "\n",
        "        loss = loss + np.sum(sub_loss)\n",
        "        seed = np.random.randint(100000)\n",
        "        history = cnn_module.train(CNN_X, V, item_weight, seed)\n",
        "        theta = cnn_module.get_projection_layer(CNN_X)\n",
        "        cnn_loss = history.history['loss'][-1]\n",
        "\n",
        "        loss = loss - 0.5 * lambda_v * cnn_loss * num_item\n",
        "\n",
        "        tr_eval = eval_RMSE(Train_R_I, U, V, train_user[0])\n",
        "        val_eval = eval_RMSE(Valid_R, U, V, valid_user[0])\n",
        "        te_eval = eval_RMSE(Test_R, U, V, test_user[0])\n",
        "\n",
        "        toc = time.time()\n",
        "        elapsed = toc - tic\n",
        "\n",
        "        converge = abs((loss - PREV_LOSS) / PREV_LOSS)\n",
        "\n",
        "        if (val_eval < pre_val_eval):\n",
        "            cnn_module.save_model(res_dir + '/CNN_weights.hdf5')\n",
        "            np.savetxt(res_dir + '/U.dat', U)\n",
        "            np.savetxt(res_dir + '/V.dat', V)\n",
        "            np.savetxt(res_dir + '/theta.dat', theta)\n",
        "        else:\n",
        "            count = count + 1\n",
        "\n",
        "        pre_val_eval = val_eval\n",
        "\n",
        "        print \"Loss: %.5f Elpased: %.4fs Converge: %.6f Tr: %.5f Val: %.5f Te: %.5f\" % (\n",
        "            loss, elapsed, converge, tr_eval, val_eval, te_eval)\n",
        "        f1.write(\"Loss: %.5f Elpased: %.4fs Converge: %.6f Tr: %.5f Val: %.5f Te: %.5f\\n\" % (\n",
        "            loss, elapsed, converge, tr_eval, val_eval, te_eval))\n",
        "\n",
        "        if (count == endure_count):\n",
        "            break\n",
        "\n",
        "        PREV_LOSS = loss\n",
        "\n",
        "    f1.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}